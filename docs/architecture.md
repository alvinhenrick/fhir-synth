# Architecture

## System Overview

```mermaid
graph TB
    subgraph UI["ðŸ–¥ï¸ User Interface"]
        CLI["CLI (Typer)\ngenerate Â· rules Â· codegen Â· bundle"]
        API["Python API\nCodeGenerator Â· RuleEngine\nBundleBuilder Â· FHIRResourceFactory"]
    end

    subgraph CORE["âš™ï¸ Core Modules"]
        CG["code_generator/\nCodeGenerator Â· PromptToRulesConverter\nexecutor Â· prompts Â· constants Â· utils"]
        RE["rule_engine/\nRuleEngine Â· Rule Â· RuleSet\nGenerationRules Â· EMPI"]
        BB["bundle/\nBundleBuilder Â· BundleManager\nBundleFactory"]
        FU["fhir_utils/\nFHIRResourceFactory\nLazyResourceMap"]
        FS["fhir_spec.py\nAuto-discovery of all\n141 R4B resource types"]
    end

    subgraph LLM_LAYER["ðŸ¤– LLM Layer"]
        LLM["llm.py\nLLMProvider Â· MockLLMProvider\nget_provider()"]
        LITELLM["LiteLLM\nOpenAI Â· Anthropic Â· Bedrock\nAzure Â· 100+ providers"]
    end

    subgraph FHIR["ðŸ¥ FHIR Foundation"]
        FR["fhir.resources (R4B)\nPydantic models for all\nFHIR resource types"]
    end

    CLI --> CG
    CLI --> RE
    CLI --> BB
    API --> CG
    API --> RE
    API --> BB
    API --> FU

    CG --> LLM
    CG --> FS
    RE --> FS
    BB --> RE
    BB --> FS
    FU --> FS
    LLM --> LITELLM
    FS --> FR
    FU --> FR
```

---

## Generate Command â€” Data Flow

The primary workflow: prompt â†’ LLM â†’ code â†’ safety checks â†’ sandbox exec â†’ smoke test â†’ FHIR Bundle.

```mermaid
sequenceDiagram
    autonumber
    participant U as ðŸ‘¤ User
    participant CLI as ðŸ–¥ï¸ CLI
    participant CG as âš™ï¸ CodeGenerator
    participant LLM as ðŸ¤– LLMProvider
    participant EX as ðŸ”’ Executor
    participant BB as ðŸ“¦ BundleBuilder
    participant F as ðŸ’¾ File

    U->>CLI: fhir-synth generate "10 diabetic patients" -o out.json
    CLI->>CG: generate_code_from_prompt(prompt)

    Note over CG,LLM: System prompt includes FHIR spec,<br/>sandbox constraints, import guide
    CG->>LLM: generate_text(system_prompt, user_prompt)
    LLM-->>CG: Python code (fhir.resources)
    CG->>CG: extract_code() â€” strip markdown fences
    CG-->>CLI: code string

    CLI->>CG: execute_generated_code(code)
    CG->>CG: validate_imports() + fix_common_imports()
    CG->>CG: validate_code() â€” syntax + safety checks

    CG->>EX: execute_code(code)
    Note over EX: Pre-flight: import whitelist + dangerous builtins
    Note over EX: Auto-fix: naive datetime.now() â†’ UTC
    EX->>EX: Subprocess: exec(code) â†’ generate_resources()
    EX->>EX: Smoke test: validate output

    alt âŒ Execution or smoke test fails
        EX-->>CG: error message
        CG->>LLM: build_fix_prompt(code, error)
        LLM-->>CG: fixed code
        CG->>EX: execute_code(fixed_code)
    end

    EX-->>CG: list[dict] resources
    CG-->>CLI: resources

    CLI->>BB: add_resources(resources)
    CLI->>BB: build()
    BB-->>CLI: FHIR Bundle dict

    CLI->>F: write JSON / NDJSON
    CLI-->>U: âœ“ Bundle â†’ out.json (or per-patient with --split)
```

---

## Self-Healing Code Execution

When LLM-generated code fails, the error is automatically sent back to the LLM for correction (up to 2 retries). The fix prompt includes the error, the failing code, the FHIR import guide, and specific hints for common error types.

```mermaid
flowchart TD
    A["ðŸ¤– LLM generates Python code"] --> B["ðŸ” Pre-flight safety checks"]
    B --> B1{"Import whitelist?"}
    B1 -->|"Disallowed import"| FIX["ðŸ“¤ Auto-fix imports or send error to LLM"]
    B1 -->|Pass| B2{"Dangerous builtins?"}
    B2 -->|"eval/exec/open"| REJECT["âœ— Reject code"]
    B2 -->|Pass| B3["ðŸ”§ Auto-fix naive datetime.now()"]
    B3 --> C["ðŸ”’ Execute in subprocess"]
    C --> D{"âœ… Execution OK?"}
    D -->|"Runtime error"| RETRY
    D -->|Pass| E["ðŸ§ª Smoke test output"]
    E --> E1{"Non-empty list?"}
    E1 -->|Empty| RETRY
    E1 -->|Pass| E2{"Every dict has resourceType?"}
    E2 -->|Missing| RETRY
    E2 -->|Pass| F["âœ“ Return resources"]

    RETRY{"ðŸ”„ Retries left?"}
    RETRY -->|"Yes (max 2)"| FIX2["ðŸ“¤ Send error + code to LLM"]
    RETRY -->|No| H["âœ— Raise RuntimeError"]
    FIX2 --> G["ðŸ¤– LLM returns fixed code"]
    FIX --> G
    G --> B
```

### Error types handled by self-healing

| Error | Auto-fix | LLM hint |
|---|---|---|
| Wrong fhir.resources import path | `fix_common_imports()` rewrites the import | Import guide with correct module paths |
| `datetime.now()` without timezone | Source rewrite to `datetime.now(timezone.utc)` | "Add timezone offset" |
| Disallowed import (`os`, `socket`, etc.) | â€” | "Replace with allowed alternative" |
| Pydantic `ValidationError` | â€” | "Fix the invalid field value" |
| Missing required field (`status`, etc.) | â€” | "Add the missing required field" |
| Missing `resourceType` in output | â€” | "Use `.model_dump(exclude_none=True)`" |
| Empty result list | â€” | "Ensure non-empty list" |

---

## FHIR Spec Introspection

At import time, `fhir_spec.py` scans the `fhir.resources.R4B` package and builds:

- **Module map**: `{ClassName: module_name}` for all ~141 resource types
- **Required fields**: detected via both Pydantic `is_required()` and `fhir.resources`' custom `element_required` marker
- **Reference fields**: fields with `ReferenceType` annotation
- **Import guide**: exact `from fhir.resources.R4B.{module} import {Class}` paths

This spec is injected into LLM prompts so the model knows the correct import paths and required fields for every resource type.

---

## Key Design Decisions

### LLM Integration via LiteLLM

All LLM calls go through a thin `LLMProvider` abstraction backed by [LiteLLM](https://docs.litellm.ai/), supporting 100+ providers (OpenAI, Anthropic, Bedrock, Azure, etc.) with a single interface. A `MockLLMProvider` enables testing without API keys.

### Dynamic System Prompt

The system prompt is assembled dynamically from:

- **Sandbox constraints** â€” built from `ALLOWED_MODULES` in `constants.py`
- **FHIR spec summary** â€” required/optional/reference fields per resource type
- **Import guide** â€” introspected `from fhir.resources.R4B.{mod} import {Cls}` paths
- **Reference field map** â€” exact field names for Patient/Encounter/etc. linkage
- **Chain-of-thought** â€” step-by-step instructions for code generation

### Custom Metadata

Metadata (security labels, tags, profiles, source) is configured via YAML (`--meta-config`):

```yaml
meta:
  security:
    - system: "http://terminology.hl7.org/CodeSystem/v3-Confidentiality"
      code: "N"
      display: "Normal"
  tag:
    - system: "http://example.org/tags"
      code: "synthetic-data"
  source: "http://example.org/fhir-synth"
```

### Output Modes

| Flag | Output |
|---|---|
| *(default)* | Single JSON â€” one Bundle with all patients |
| `--split` | One JSON file per patient in output directory |
